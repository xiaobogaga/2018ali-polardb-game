# version 2
我们已经开始用多个文件来保存所有的数据，以及用version号来标明次序。在我们提交程序后我们发现程序经常oom，
实际上我们的程序占用的内存并不多，我开始怀疑是jvm parameters设置错误2560m + 500(测试程序)几乎有3g，超出限制。

* 修改jvm parameters -> 2000m.

* 对key updateVersion使用AtomicInter + ConcurrentHashMap(乐观锁)


# version 3. optimize read.

the base idea is that when we generate all keys, there are 10000000 (千万) 的不同数据集。如果我们
计算这些10000000


# version 4.

我们初始向的很多都错误了。尽管我们用多个文件来保存数据并发写入，但是线程竞争带来的提高不明显。我们开始使用单文件。
我们尝试4KB对齐。另一个发现是大的HashTable使得整个文件占用太多的内存，这一块我们打算优化.
